library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
#Para saber cual es el mejor numero de clusters
wss <- (nrow(trainImportantes)-1)*sum(apply(trainImportantes,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(trainImportantes, centers=i)$withinss)
# Se plotea la grafica de codo
plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
#Visualización de las k-medias
fviz_cluster(km, data = trainImportantes,geom = "point", ellipse.type = "norm")
#-----------------------------------------------------------------------------------------------
#Silueta de que tan bien hizo el cluster
silkm<-silhouette(km$cluster,dist(trainImportantes))
mean(silkm[,3])
g1<- train[train$grupo==1,]
g2<- train[train$grupo==2,]
g3<- train[train$grupo==3,]
trainTree <- train[c("YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
#rpart.plot(dt_model)
prediccion <- predict(dt_model, newdata = test1[,1:6])
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
test1$prediccion<-columnaMasAlta #Se le aÃ±ade al grupo de prueba el valor de la predicciÃ³n
#View(test1)
cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
cfm
plotcluster(trainImportantes,km$cluster)
source('C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria/HDT3.R', echo=TRUE)
trainImportantes$grupo<-km$cluster
km<-kmeans(trainImportantes,3)
trainImportantes$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
train$grupo<-km$cluster
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
#setwd("C:/Users/alber/Documents/UVG/Septimo semestre/Mineria de Datos/Hoja_Trabajo_3/HDT3-Mineria")
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
#Para saber cual es el mejor numero de clusters
wss <- (nrow(trainImportantes)-1)*sum(apply(trainImportantes,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(trainImportantes, centers=i)$withinss)
# Se plotea la grafica de codo
plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
#Visualización de las k-medias
fviz_cluster(km, data = trainImportantes,geom = "point", ellipse.type = "norm")
#-----------------------------------------------------------------------------------------------
#Silueta de que tan bien hizo el cluster
silkm<-silhouette(km$cluster,dist(trainImportantes))
mean(silkm[,3])
trainTree <- train[c("YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
#rpart.plot(dt_model)
prediccion <- predict(dt_model, newdata = test1[,1:6])
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
#Para saber cual es el mejor numero de clusters
wss <- (nrow(trainImportantes)-1)*sum(apply(trainImportantes,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(trainImportantes, centers=i)$withinss)
# Se plotea la grafica de codo
plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
#Visualización de las k-medias
fviz_cluster(km, data = trainImportantes,geom = "point", ellipse.type = "norm")
#-----------------------------------------------------------------------------------------------
#Silueta de que tan bien hizo el cluster
silkm<-silhouette(km$cluster,dist(trainImportantes))
mean(silkm[,3])
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
#rpart.plot(dt_model)
prediccion <- predict(dt_model, newdata = test1[,1:6])
#rpart.plot(dt_model)
prediccion <- predict(dt_model, newdata = test1[,1:7])
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
test1$prediccion<-columnaMasAlta #Se le aÃ±ade al grupo de prueba el valor de la predicciÃ³n
#View(test1)
cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
cfm
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
plotcluster(trainImportantes,km$cluster)
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#---------------------------------------------------------------------
porciento <- 70/100
set.seed(18)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_modelR<-rpart(grupo~.,train1,method = "anova")
plot(dt_modelR);text(dt_modelR)
prp(dt_modelR)
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
#rpart.plot(dt_model)
prediccion <- predict(dt_model, newdata = test1[,1:7])
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
test1$prediccion<-columnaMasAlta #Se le aÃ±ade al grupo de prueba el valor de la predicciÃ³n
#View(test1)
cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
cfm
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
dt_model<-rpart(grupo~.,train1,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
#rpart.plot(dt_model)
prediccion <- predict(dt_model, newdata = test1[,1:7])
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
test1$prediccion<-columnaMasAlta #Se le aÃ±ade al grupo de prueba el valor de la predicciÃ³n
#View(test1)
cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
View(head(train1))
View(head(test1))
View(head(test))
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
View(head(test))
#cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
#cfm
#------------------------------------------------------------------ con random forest
modeloRF1<-randomForest(grupo~.,data=train1)
prediccionRF1<-predict(modeloRF1,newdata = test1[,1:6])
testCompleto<-test1
testCompleto$predRF<-prediccionRF1
cfmRandomForest <- confusionMatrix(table(testCompleto$predRF, testCompleto$grupo))
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
#cfm
#------------------------------------------------------------------ con random forest
modeloRF1<-randomForest(grupo~.,data=train1)
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
datos <- iris
set.seed(123)
trainRowsNumber<-sample(1:nrow(datos),porciento*nrow(datos))
# variable respuesta la clase de la flor
porciento <- 70/100
set.seed(123)
trainRowsNumber<-sample(1:nrow(datos),porciento*nrow(datos))
train<-datos[trainRowsNumber,]
test<-datos[-trainRowsNumber,]
#con random forest
modeloRF1<-randomForest(Species~.,data=train)
prediccionRF1<-predict(modeloRF1,newdata = test)
testCompleto<-test
testCompleto$predRF<-prediccionRF1
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$Species)
cfmRandomForest
#cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
#cfm
#------------------------------------------------------------------ con random forest
modeloRF1<-randomForest(grupo~.,data=trainTree)
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
#cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
#cfm
#------------------------------------------------------------------ con random forest
modeloRF1<-randomForest(grupo~.,data=train1)
prediccionRF1<-predict(modeloRF1,newdata = test1[,1:7])
testCompleto<-test1
testCompleto$predRF<-prediccionRF1
cfmRandomForest <- confusionMatrix(table(testCompleto$predRF, testCompleto$grupo))
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$grupo)
?confusionMatrix
View(head(testCompleto))
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
datos <- iris
# variable respuesta la clase de la flor
porciento <- 70/100
set.seed(123)
trainRowsNumber<-sample(1:nrow(datos),porciento*nrow(datos))
train<-datos[trainRowsNumber,]
test<-datos[-trainRowsNumber,]
#con random forest
modeloRF1<-randomForest(Species~.,data=train)
prediccionRF1<-predict(modeloRF1,newdata = test)
testCompleto<-test
testCompleto$predRF<-prediccionRF1
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$Species)
View(head(testCompleto))
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
#cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
#cfm
#------------------------------------------------------------------ con random forest
modeloRF1<-randomForest(grupo~.,data=train1)
prediccionRF1<-predict(modeloRF1,newdata = test1[,1:7])
prediccionRF1
round(prediccionRF1,digits = 1)
trunc(2.3)
trunc(2.5)
trunc(2.6)
trunc(2.99)
ceiling(2.99)
ceiling(2.79)
ceiling(2.39)
ceiling(2.19)
?round()
round(2.19)
round(2.19)
round(2.49)
round(2.59)
round(prediccionRF1)
testCompleto$predRF<-round(prediccionRF1)
setwd("C:/Users/Gustavo/Desktop/SEPTIMO SEMESTRE/MINERIA/HDT3/HDT3-Mineria")
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(tidyr)
library(splitstackshape)
test <- read.csv("test.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
trainImportantes <- train[c("MSSubClass","LotFrontage","LotArea","OverallCond","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","TotRmsAbvGrd","KitchenAbvGr","GarageCars","PoolArea","SalePrice")]
trainImportantes[is.na(trainImportantes)]<-0
km<-kmeans(trainImportantes,3)
train$grupo<-km$cluster
trainTree <- train[c("LotArea","YearBuilt","YearRemodAdd","X2ndFlrSF","FullBath","KitchenAbvGr","GarageCars","grupo")]
#-----------------------------------------------------------------------------------------------
porciento <- 70/100
set.seed(2)
trainRowsNumber<-sample(1:nrow(trainTree),porciento*nrow(trainTree))
train1<-trainTree[trainRowsNumber,]
test1<-trainTree[-trainRowsNumber,]
#cfm<-confusionMatrix(table(test1$prediccion, test1$grupo))
#cfm
#------------------------------------------------------------------ con random forest
modeloRF1<-randomForest(grupo~.,data=train1)
prediccionRF1<-predict(modeloRF1,newdata = test1[,1:7])
testCompleto<-test1
testCompleto$predRF<-round(prediccionRF1)
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$grupo)
View(testCompleto)
?confusionMatrix
cfmRandomForest <- confusionMatrix(table(testCompleto$predRF, testCompleto$Species))
nrow(testCompleto)
nrow(testCompleto$predRF)
testCompleto$predRF
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$grupo)
cfmRandomForest <- confusionMatrix(table(testCompleto$predRF, testCompleto$grupo))
cfmRandomForest
